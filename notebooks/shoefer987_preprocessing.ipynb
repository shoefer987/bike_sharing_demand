{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bikesharing.ml_logic.data import get_raw_data ,get_weather_data ,get_polygons\n",
    "from bikesharing.params import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove duplicates\n",
    "- Deal with missing values\n",
    "- Scale the features\n",
    "- Encode features\n",
    "- Perform cyclical engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23698/1700516227.py:4: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'../raw_data/MVG_Rad_Fahrten_{year}.csv', sep=';')\n",
      "/tmp/ipykernel_23698/1700516227.py:4: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'../raw_data/MVG_Rad_Fahrten_{year}.csv', sep=';')\n",
      "/tmp/ipykernel_23698/1700516227.py:4: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'../raw_data/MVG_Rad_Fahrten_{year}.csv', sep=';')\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "meta = {'years':[], 'n_columns':[], 'n_rows':[]}\n",
    "for year in range(2019,2023,1):\n",
    "    df = pd.read_csv(f'../raw_data/MVG_Rad_Fahrten_{year}.csv', sep=';')\n",
    "    cols = [col.strip() for col in df.columns]\n",
    "    df.columns = cols\n",
    "    dfs.append(df)\n",
    "    meta['years'].append(year)\n",
    "    meta['n_columns'].append(df.shape[1])\n",
    "    meta['n_rows'].append(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753678, 11)\n",
      "(721752, 11)\n",
      "(619573, 11)\n",
      "(709144, 11)\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_df(df):\n",
    "  #vstrip column names\n",
    "  cols = [col.strip() for col in df.columns]\n",
    "  df.columns = cols\n",
    "\n",
    "  # remove column 'Row'\n",
    "  if 'Row' in df.columns:\n",
    "    df.drop(columns='Row', inplace=True)\n",
    "\n",
    "  # select relevant columns only\n",
    "  #df = df[['STARTTIME', 'STARTLAT', 'STARTLON', 'RENTAL_IS_STATION']].copy()\n",
    "  \n",
    "  # make string replacements values\n",
    "  df_obj = df.select_dtypes(include='object')\n",
    "  df[df_obj.columns] = df_obj.applymap(lambda x: x.strip().replace(',', '.') if isinstance(x, str) else x)\n",
    "\n",
    "  # handle datetime\n",
    "  df.STARTTIME = pd.to_datetime(df.STARTTIME)\n",
    "\n",
    "  # handle numeric columns\n",
    "  df.replace('NULL', np.NAN, inplace=True)\n",
    "  df.replace('', np.NAN, inplace=True)\n",
    "  df[['STARTLAT', 'STARTLON', 'RENTAL_IS_STATION','ENDLAT', 'ENDLON', 'RETURN_IS_STATION']] = df[['STARTLAT', 'STARTLON', 'RENTAL_IS_STATION','ENDLAT', 'ENDLON', 'RETURN_IS_STATION']].astype(np.float32)\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m pre_process_df(data)\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mpre_process_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# select relevant columns only\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m#df = df[['STARTTIME', 'STARTLAT', 'STARTLON', 'RENTAL_IS_STATION']].copy()\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[39m# make string replacements values\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df_obj \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mselect_dtypes(include\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m df[df_obj\u001b[39m.\u001b[39mcolumns] \u001b[39m=\u001b[39m df_obj\u001b[39m.\u001b[39;49mapplymap(\u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mstrip()\u001b[39m.\u001b[39;49mreplace(\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(x, \u001b[39mstr\u001b[39;49m) \u001b[39melse\u001b[39;49;00m x)\n\u001b[1;32m     17\u001b[0m \u001b[39m# handle datetime\u001b[39;00m\n\u001b[1;32m     18\u001b[0m df\u001b[39m.\u001b[39mSTARTTIME \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39mSTARTTIME)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/frame.py:9508\u001b[0m, in \u001b[0;36mDataFrame.applymap\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m   9505\u001b[0m         \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(x, func, ignore_na\u001b[39m=\u001b[39mignore_na)\n\u001b[1;32m   9506\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(x\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values, func, ignore_na\u001b[39m=\u001b[39mignore_na)\n\u001b[0;32m-> 9508\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(infer)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mapplymap\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/frame.py:9506\u001b[0m, in \u001b[0;36mDataFrame.applymap.<locals>.infer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   9504\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mempty:\n\u001b[1;32m   9505\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(x, func, ignore_na\u001b[39m=\u001b[39mignore_na)\n\u001b[0;32m-> 9506\u001b[0m \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(x\u001b[39m.\u001b[39;49mastype(\u001b[39mobject\u001b[39;49m)\u001b[39m.\u001b[39;49m_values, func, ignore_na\u001b[39m=\u001b[39;49mignore_na)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mpre_process_df.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# select relevant columns only\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m#df = df[['STARTTIME', 'STARTLAT', 'STARTLON', 'RENTAL_IS_STATION']].copy()\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[39m# make string replacements values\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df_obj \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mselect_dtypes(include\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m df[df_obj\u001b[39m.\u001b[39mcolumns] \u001b[39m=\u001b[39m df_obj\u001b[39m.\u001b[39mapplymap(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49mstrip()\u001b[39m.\u001b[39;49mreplace(\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m x)\n\u001b[1;32m     17\u001b[0m \u001b[39m# handle datetime\u001b[39;00m\n\u001b[1;32m     18\u001b[0m df\u001b[39m.\u001b[39mSTARTTIME \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39mSTARTTIME)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = pre_process_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_bq(\n",
    "        data: pd.DataFrame,\n",
    "        gcp_project:str,\n",
    "        bq_dataset:str,\n",
    "        table: str,\n",
    "        truncate: bool\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    - Save the DataFrame to BigQuery\n",
    "    - Empty the table beforehand if `truncate` is True, append otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(data, pd.DataFrame)\n",
    "    full_table_name = f\"{gcp_project}.{bq_dataset}.{table}\"\n",
    "\n",
    "    #print(Fore.BLUE + f\"\\nSave data to BigQuery @ {full_table_name}...:\" + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "    # reset column names\n",
    "    data.columns = [f'_{col}' if isinstance(col, int) else col for col in data.columns]\n",
    "\n",
    "    # Load data onto full_table_name\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    write_mode = \"WRITE_TRUNCATE\" if truncate else \"WRITE_APPEND\"\n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=write_mode)\n",
    "\n",
    "    job = client.load_table_from_dataframe(data, full_table_name, job_config=job_config)\n",
    "\n",
    "    # ðŸŽ¯ HINT for \"*** TypeError: expected bytes, int found\":\n",
    "    # After preprocessing the data, your original column names are gone (print it to check),\n",
    "    # so ensure that your column names are *strings* that start with either\n",
    "    # a *letter* or an *underscore*, as BQ does not accept anything else\n",
    "\n",
    "    print(f\"âœ… Data saved to bigquery, with shape {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2804147 entries, 0 to 709143\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   STARTTIME            datetime64[ns]\n",
      " 1   ENDTIME              object        \n",
      " 2   STARTLAT             float32       \n",
      " 3   STARTLON             float32       \n",
      " 4   ENDLAT               float32       \n",
      " 5   ENDLON               float32       \n",
      " 6   RENTAL_IS_STATION    float32       \n",
      " 7   RENTAL_STATION_NAME  object        \n",
      " 8   RETURN_IS_STATION    float32       \n",
      " 9   RETURN_STATION_NAME  object        \n",
      "dtypes: datetime64[ns](1), float32(6), object(3)\n",
      "memory usage: 171.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data saved to bigquery, with shape (2804147, 10)\n"
     ]
    }
   ],
   "source": [
    "load_data_to_bq(\n",
    "        data=data,\n",
    "        gcp_project=os.environ.get(\"GCP_PROJECT\"),\n",
    "        bq_dataset=os.environ.get(\"BQ_DATASET\"),\n",
    "        table='raw_data_mvg',\n",
    "        truncate=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =f'''\n",
    "        SELECT *\n",
    "        FROM `{GCP_PROJECT}.{BQ_DATASET}.raw_data_mvg`\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load rental_data from BigQuery server...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m get_raw_data(GCP_PROJECT, query\u001b[39m=\u001b[39;49mquery, cache_path\u001b[39m=\u001b[39;49mPath(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mLOCAL_DATA_PATH\u001b[39m}\u001b[39;49;00m\u001b[39m/raw/MVG_Rad_Fahrten_\u001b[39;49m\u001b[39m{\u001b[39;49;00mSTART_YEAR\u001b[39m}\u001b[39;49;00m\u001b[39m_to_\u001b[39;49m\u001b[39m{\u001b[39;49;00mEND_YEAR\u001b[39m}\u001b[39;49;00m\u001b[39m.csv\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      2\u001b[0m df\n",
      "File \u001b[0;32m~/code/shoefer987/bike_sharing_demand/bikesharing/ml_logic/data.py:37\u001b[0m, in \u001b[0;36mget_raw_data\u001b[0;34m(gcp_project, query, cache_path, data_has_header)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mprint\u001b[39m(Fore\u001b[39m.\u001b[39mBLUE \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mLoad rental_data from BigQuery server...\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m Style\u001b[39m.\u001b[39mRESET_ALL)\n\u001b[1;32m     36\u001b[0m client \u001b[39m=\u001b[39m bigquery\u001b[39m.\u001b[39mClient(project\u001b[39m=\u001b[39mgcp_project)\n\u001b[0;32m---> 37\u001b[0m query_job \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mquery(query)\n\u001b[1;32m     38\u001b[0m result \u001b[39m=\u001b[39m query_job\u001b[39m.\u001b[39mresult()\n\u001b[1;32m     39\u001b[0m df \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mto_dataframe()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/cloud/bigquery/client.py:3403\u001b[0m, in \u001b[0;36mClient.query\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[1;32m   3392\u001b[0m     \u001b[39mreturn\u001b[39;00m _job_helpers\u001b[39m.\u001b[39mquery_jobs_query(\n\u001b[1;32m   3393\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   3394\u001b[0m         query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3400\u001b[0m         job_retry,\n\u001b[1;32m   3401\u001b[0m     )\n\u001b[1;32m   3402\u001b[0m \u001b[39melif\u001b[39;00m api_method \u001b[39m==\u001b[39m enums\u001b[39m.\u001b[39mQueryApiMethod\u001b[39m.\u001b[39mINSERT:\n\u001b[0;32m-> 3403\u001b[0m     \u001b[39mreturn\u001b[39;00m _job_helpers\u001b[39m.\u001b[39;49mquery_jobs_insert(\n\u001b[1;32m   3404\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3405\u001b[0m         query,\n\u001b[1;32m   3406\u001b[0m         job_config,\n\u001b[1;32m   3407\u001b[0m         job_id,\n\u001b[1;32m   3408\u001b[0m         job_id_prefix,\n\u001b[1;32m   3409\u001b[0m         location,\n\u001b[1;32m   3410\u001b[0m         project,\n\u001b[1;32m   3411\u001b[0m         retry,\n\u001b[1;32m   3412\u001b[0m         timeout,\n\u001b[1;32m   3413\u001b[0m         job_retry,\n\u001b[1;32m   3414\u001b[0m     )\n\u001b[1;32m   3415\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3416\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot unexpected value for api_method: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(api_method)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/cloud/bigquery/_job_helpers.py:114\u001b[0m, in \u001b[0;36mquery_jobs_insert\u001b[0;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m         \u001b[39mreturn\u001b[39;00m query_job\n\u001b[0;32m--> 114\u001b[0m future \u001b[39m=\u001b[39m do_query()\n\u001b[1;32m    115\u001b[0m \u001b[39m# The future might be in a failed state now, but if it's\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m# unrecoverable, we'll find out when we ask for it's result, at which\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m# point, we may retry.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m job_id_given:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/cloud/bigquery/_job_helpers.py:91\u001b[0m, in \u001b[0;36mquery_jobs_insert.<locals>.do_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m query_job \u001b[39m=\u001b[39m job\u001b[39m.\u001b[39mQueryJob(job_ref, query, client\u001b[39m=\u001b[39mclient, job_config\u001b[39m=\u001b[39mjob_config)\n\u001b[1;32m     90\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     query_job\u001b[39m.\u001b[39;49m_begin(retry\u001b[39m=\u001b[39;49mretry, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m     92\u001b[0m \u001b[39mexcept\u001b[39;00m core_exceptions\u001b[39m.\u001b[39mConflict \u001b[39mas\u001b[39;00m create_exc:\n\u001b[1;32m     93\u001b[0m     \u001b[39m# The thought is if someone is providing their own job IDs and they get\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[39m# their job ID generation wrong, this could end up returning results for\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[39m# the wrong query. We thus only try to recover if job ID was not given.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m job_id_given:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1310\u001b[0m, in \u001b[0;36mQueryJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"API call:  begin the job via a POST request\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \n\u001b[1;32m   1292\u001b[0m \u001b[39mSee\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[39m    ValueError: If the job has already begun.\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1310\u001b[0m     \u001b[39msuper\u001b[39;49m(QueryJob, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_begin(client\u001b[39m=\u001b[39;49mclient, retry\u001b[39m=\u001b[39;49mretry, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1311\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mGoogleAPICallError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m   1312\u001b[0m     exc\u001b[39m.\u001b[39mmessage \u001b[39m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1313\u001b[0m         message\u001b[39m=\u001b[39mexc\u001b[39m.\u001b[39mmessage, location\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocation, job_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob_id\n\u001b[1;32m   1314\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py:693\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[39m# job has an ID.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m span_attributes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m: path}\n\u001b[0;32m--> 693\u001b[0m api_response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49m_call_api(\n\u001b[1;32m    694\u001b[0m     retry,\n\u001b[1;32m    695\u001b[0m     span_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mBigQuery.job.begin\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    696\u001b[0m     span_attributes\u001b[39m=\u001b[39;49mspan_attributes,\n\u001b[1;32m    697\u001b[0m     job_ref\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    698\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    699\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m    700\u001b[0m     data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_api_repr(),\n\u001b[1;32m    701\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    702\u001b[0m )\n\u001b[1;32m    703\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_properties(api_response)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/cloud/bigquery/client.py:813\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[39mif\u001b[39;00m span_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m     \u001b[39mwith\u001b[39;00m create_span(\n\u001b[1;32m    811\u001b[0m         name\u001b[39m=\u001b[39mspan_name, attributes\u001b[39m=\u001b[39mspan_attributes, client\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, job_ref\u001b[39m=\u001b[39mjob_ref\n\u001b[1;32m    812\u001b[0m     ):\n\u001b[0;32m--> 813\u001b[0m         \u001b[39mreturn\u001b[39;00m call()\n\u001b[1;32m    815\u001b[0m \u001b[39mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    350\u001b[0m     target,\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[1;32m    352\u001b[0m     sleep_generator,\n\u001b[1;32m    353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[1;32m    354\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[39mreturn\u001b[39;00m target()\n\u001b[1;32m    193\u001b[0m     \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/cloud/_http/__init__.py:482\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    479\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(data)\n\u001b[1;32m    480\u001b[0m     content_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 482\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    483\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    484\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    485\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    486\u001b[0m     content_type\u001b[39m=\u001b[39;49mcontent_type,\n\u001b[1;32m    487\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    488\u001b[0m     target_object\u001b[39m=\u001b[39;49m_target_object,\n\u001b[1;32m    489\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    490\u001b[0m     extra_api_info\u001b[39m=\u001b[39;49mextra_api_info,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m    494\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_http_response(response)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/cloud/_http/__init__.py:341\u001b[0m, in \u001b[0;36mJSONConnection._make_request\u001b[0;34m(self, method, url, data, content_type, headers, target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    338\u001b[0m     headers[CLIENT_INFO_HEADER] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_agent\n\u001b[1;32m    339\u001b[0m headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_agent\n\u001b[0;32m--> 341\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_request(\n\u001b[1;32m    342\u001b[0m     method, url, headers, data, target_object, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    343\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/cloud/_http/__init__.py:379\u001b[0m, in \u001b[0;36mJSONConnection._do_request\u001b[0;34m(self, method, url, headers, data, target_object, timeout)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_request\u001b[39m(\n\u001b[1;32m    346\u001b[0m     \u001b[39mself\u001b[39m, method, url, headers, data, target_object, timeout\u001b[39m=\u001b[39m_DEFAULT_TIMEOUT\n\u001b[1;32m    347\u001b[0m ):  \u001b[39m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Low-level helper:  perform the actual API request over HTTP.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[1;32m    350\u001b[0m \u001b[39m    Allows batch context managers to override and defer a request.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39m    :returns: The HTTP response.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhttp\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    380\u001b[0m         url\u001b[39m=\u001b[39;49murl, method\u001b[39m=\u001b[39;49mmethod, headers\u001b[39m=\u001b[39;49mheaders, data\u001b[39m=\u001b[39;49mdata, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    381\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/google/auth/transport/requests.py:549\u001b[0m, in \u001b[0;36mAuthorizedSession.request\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m remaining_time \u001b[39m=\u001b[39m guard\u001b[39m.\u001b[39mremaining_timeout\n\u001b[1;32m    548\u001b[0m \u001b[39mwith\u001b[39;00m TimeoutGuard(remaining_time) \u001b[39mas\u001b[39;00m guard:\n\u001b[0;32m--> 549\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(AuthorizedSession, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    550\u001b[0m         method,\n\u001b[1;32m    551\u001b[0m         url,\n\u001b[1;32m    552\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    553\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest_headers,\n\u001b[1;32m    554\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    555\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    556\u001b[0m     )\n\u001b[1;32m    557\u001b[0m remaining_time \u001b[39m=\u001b[39m guard\u001b[39m.\u001b[39mremaining_timeout\n\u001b[1;32m    559\u001b[0m \u001b[39m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[39m# request.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[39m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# the time the request is made, so we may need to try twice.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    462\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = get_raw_data(GCP_PROJECT, query=query, cache_path=Path(f'{LOCAL_DATA_PATH}/raw/MVG_Rad_Fahrten_{START_YEAR}_to_{END_YEAR}.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "base_url = 'https://archive-api.open-meteo.com/v1/archive'\n",
    "\n",
    "params = {\n",
    "    'latitude': 48.70,\n",
    "    'longitude': 13.46,\n",
    "    'start_date' : f'{START_YEAR}-01-01',\n",
    "    'end_date' : f'{END_YEAR}-12-31',\n",
    "    'hourly': ['temperature_2m', 'relativehumidity_2m', 'apparent_temperature','windspeed_10m','precipitation']\n",
    "}\n",
    "\n",
    "historical_weather_data = requests.get(base_url , params=params).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load data from local CSV...\u001b[0m\n",
      "âœ… Data loaded, with shape (35064, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relativehumidity_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>windspeed_10m</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01T00:00</td>\n",
       "      <td>3.3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01T01:00</td>\n",
       "      <td>3.4</td>\n",
       "      <td>99</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01T02:00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01T03:00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01T04:00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2022-12-31T19:00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>83</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2022-12-31T20:00</td>\n",
       "      <td>5.9</td>\n",
       "      <td>83</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2022-12-31T21:00</td>\n",
       "      <td>5.8</td>\n",
       "      <td>81</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2022-12-31T22:00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>78</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>2022-12-31T23:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>77</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time  temperature_2m  relativehumidity_2m  \\\n",
       "0      2019-01-01T00:00             3.3                  100   \n",
       "1      2019-01-01T01:00             3.4                   99   \n",
       "2      2019-01-01T02:00             3.5                  100   \n",
       "3      2019-01-01T03:00             3.5                   99   \n",
       "4      2019-01-01T04:00             3.5                  100   \n",
       "...                 ...             ...                  ...   \n",
       "35059  2022-12-31T19:00             6.5                   83   \n",
       "35060  2022-12-31T20:00             5.9                   83   \n",
       "35061  2022-12-31T21:00             5.8                   81   \n",
       "35062  2022-12-31T22:00             6.1                   78   \n",
       "35063  2022-12-31T23:00             6.0                   77   \n",
       "\n",
       "       apparent_temperature  windspeed_10m  precipitation  \n",
       "0                       0.5            9.0            0.2  \n",
       "1                       0.4            9.7            0.1  \n",
       "2                       0.2           12.0            0.2  \n",
       "3                       0.0           13.5            0.1  \n",
       "4                      -0.0           14.1            0.0  \n",
       "...                     ...            ...            ...  \n",
       "35059                   3.9            8.0            0.0  \n",
       "35060                   3.4            6.8            0.0  \n",
       "35061                   3.1            7.2            0.0  \n",
       "35062                   3.1            8.8            0.0  \n",
       "35063                   3.3            6.8            0.0  \n",
       "\n",
       "[35064 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_weather_data(cache_path=Path(f'{LOCAL_DATA_PATH}/raw/Histotical_Weather_Data_{START_YEAR}_to_{END_YEAR}.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Maxvorstadt': <POLYGON ((11.539 48.143, 11.54 48.143, 11.542 48.143, 11.544 48.142, 11.545...>,\n",
       " 'Schwabing-West': <POLYGON ((11.55 48.161, 11.55 48.161, 11.551 48.16, 11.551 48.16, 11.552 48...>,\n",
       " 'Au - Haidhausen': <POLYGON ((11.569 48.122, 11.569 48.122, 11.569 48.122, 11.57 48.122, 11.57 ...>,\n",
       " 'Sendling': <POLYGON ((11.535 48.13, 11.536 48.13, 11.536 48.13, 11.536 48.129, 11.536 4...>,\n",
       " 'SchwanthalerhÃ¶he': <POLYGON ((11.526 48.137, 11.526 48.137, 11.526 48.136, 11.526 48.136, 11.52...>,\n",
       " 'Moosach': <POLYGON ((11.466 48.205, 11.466 48.204, 11.467 48.204, 11.468 48.204, 11.46...>,\n",
       " 'Berg am Laim': <POLYGON ((11.601 48.124, 11.602 48.124, 11.604 48.123, 11.606 48.121, 11.60...>,\n",
       " 'Trudering': <POLYGON ((11.644 48.115, 11.644 48.115, 11.646 48.114, 11.647 48.113, 11.64...>,\n",
       " 'Ramersdorf': <POLYGON ((7.14 50.718, 7.143 50.718, 7.145 50.717, 7.147 50.717, 7.147 50.7...>,\n",
       " 'Obergiesing': <POLYGON ((11.574 48.112, 11.574 48.112, 11.574 48.112, 11.574 48.112, 11.57...>,\n",
       " 'Untergiesing': <POLYGON ((11.541 48.078, 11.542 48.078, 11.542 48.078, 11.542 48.078, 11.54...>,\n",
       " 'Harlaching': <POLYGON ((11.541 48.078, 11.542 48.078, 11.542 48.078, 11.542 48.078, 11.54...>,\n",
       " 'Thalkirchen': <POLYGON ((11.528 48.083, 11.528 48.083, 11.529 48.083, 11.529 48.083, 11.52...>,\n",
       " 'Obersendling': <POLYGON ((11.503 48.092, 11.503 48.092, 11.503 48.09, 11.503 48.089, 11.503...>,\n",
       " 'Hadern': <POLYGON ((11.463 48.105, 11.464 48.105, 11.465 48.105, 11.467 48.105, 11.46...>,\n",
       " 'Pasing': <POLYGON ((11.436 48.137, 11.437 48.136, 11.439 48.135, 11.438 48.135, 11.43...>,\n",
       " 'Obermenzing': <POLYGON ((11.433 48.163, 11.437 48.161, 11.437 48.161, 11.438 48.16, 11.439...>,\n",
       " 'Lochhausen': <POLYGON ((11.379 48.179, 11.381 48.177, 11.38 48.176, 11.38 48.176, 11.381 ...>,\n",
       " 'Langwied': <POLYGON ((13.06 47.83, 13.06 47.83, 13.06 47.83, 13.06 47.83, 13.061 47.829...>,\n",
       " 'Feldmoching': <POLYGON ((11.477 48.22, 11.477 48.22, 11.478 48.22, 11.479 48.22, 11.48 48....>,\n",
       " 'Laim': <POLYGON ((11.483 48.131, 11.483 48.131, 11.483 48.13, 11.484 48.13, 11.484 ...>,\n",
       " 'Ludwigsvorstadt-Isarvorstadt': <POLYGON ((11.544 48.126, 11.544 48.126, 11.544 48.126, 11.544 48.126, 11.54...>,\n",
       " 'Ramersdorf-Perlach': <POLYGON ((11.595 48.115, 11.595 48.115, 11.595 48.115, 11.595 48.115, 11.59...>,\n",
       " 'Untermenzing-Allach': <POLYGON ((11.43 48.189, 11.431 48.188, 11.431 48.188, 11.431 48.188, 11.431...>,\n",
       " 'Hasenbergl-Lerchenau Ost': <POLYGON ((11.539 48.189, 11.539 48.189, 11.539 48.189, 11.539 48.189, 11.53...>,\n",
       " 'SÃ¼dgiesing': <POLYGON ((11.585 48.1, 11.587 48.097, 11.588 48.095, 11.588 48.095, 11.588 ...>,\n",
       " 'Altstadt-Lehel': <POLYGON ((11.565 48.136, 11.565 48.136, 11.565 48.136, 11.565 48.136, 11.56...>,\n",
       " 'Sendling-Westpark': <POLYGON ((11.501 48.103, 11.501 48.103, 11.502 48.103, 11.502 48.102, 11.50...>,\n",
       " 'Neuhausen-Nymphenburg': <POLYGON ((11.481 48.158, 11.481 48.158, 11.481 48.158, 11.481 48.157, 11.48...>,\n",
       " 'Schwabing-Freimann': <POLYGON ((11.579 48.167, 11.579 48.167, 11.579 48.165, 11.579 48.164, 11.58...>,\n",
       " 'Pasing-Obermenzing': <POLYGON ((11.433 48.163, 11.437 48.161, 11.437 48.161, 11.438 48.16, 11.439...>,\n",
       " 'Aubing-Lochhausen-Langwied': <POLYGON ((11.361 48.158, 11.361 48.158, 11.361 48.158, 11.362 48.158, 11.36...>,\n",
       " 'Milbertshofen-Am Hart': <POLYGON ((11.538 48.168, 11.538 48.168, 11.539 48.168, 11.539 48.169, 11.54...>,\n",
       " 'Bogenhausen': <POLYGON ((11.595 48.142, 11.596 48.142, 11.596 48.142, 11.596 48.142, 11.59...>,\n",
       " 'Trudering-Riem': <POLYGON ((11.644 48.115, 11.644 48.115, 11.646 48.114, 11.647 48.113, 11.64...>,\n",
       " 'Untergiesing-Harlaching': <POLYGON ((11.541 48.078, 11.542 48.078, 11.542 48.078, 11.542 48.078, 11.54...>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = get_polygons()\n",
    "dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lecture Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Sequence\n",
    "\n",
    "def get_folds(\n",
    "    df: pd.DataFrame,\n",
    "    fold_length: int,\n",
    "    fold_stride: int) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    This function slides through the Time Series dataframe of shape (n_timesteps, n_features) to create folds\n",
    "    - of equal `fold_length`\n",
    "    - using `fold_stride` between each fold\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Overall dataframe\n",
    "        fold_length (int): How long each fold should be in rows\n",
    "        fold_stride (int): How many timesteps to move forward between taking each fold\n",
    "\n",
    "    Returns:\n",
    "        List[pd.DataFrame]: A list where each fold is a dataframe within\n",
    "    \"\"\"\n",
    "    folds = []\n",
    "    for idx in range(0, len(df), fold_stride):\n",
    "        # Exits the loop as soon as the last fold index would exceed the last index\n",
    "        if (idx + fold_length) > len(df):\n",
    "            break\n",
    "        fold = df.iloc[idx:idx + fold_length, :]\n",
    "        folds.append(fold)\n",
    "    return folds\n",
    "\n",
    "def train_test_split(fold:pd.DataFrame,\n",
    "                     train_test_ratio: float,\n",
    "                     input_length: int) -> Tuple[pd.DataFrame]:\n",
    "    \"\"\"From a fold dataframe, take a train dataframe and test dataframe based on\n",
    "    the split ratio.\n",
    "    - df_train should contain all the timesteps until round(train_test_ratio * len(fold))\n",
    "    - df_test should contain all the timesteps needed to create all (X_test, y_test) tuples\n",
    "\n",
    "    Args:\n",
    "        fold (pd.DataFrame): A fold of timesteps\n",
    "        train_test_ratio (float): The ratio between train and test 0-1\n",
    "        input_length (int): How long each X_i will be\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame]: A tuple of two dataframes (fold_train, fold_test)\n",
    "    \"\"\"\n",
    "\n",
    "    # TRAIN SET\n",
    "    last_train_idx = round(train_test_ratio * len(fold))\n",
    "    fold_train = fold.iloc[0:last_train_idx, :]\n",
    "\n",
    "    # TEST SET\n",
    "    first_test_idx = last_train_idx - input_length\n",
    "    fold_test = fold.iloc[first_test_idx:, :]\n",
    "\n",
    "    return (fold_train, fold_test)\n",
    "\n",
    "def get_Xi_yi(\n",
    "    fold:pd.DataFrame,\n",
    "    input_length:int,\n",
    "    output_length:int) -> Tuple[pd.DataFrame]:\n",
    "    \"\"\"given a fold, it returns one sequence (X_i, y_i) as based on the desired\n",
    "    input_length and output_length with the starting point of the sequence being chosen at random based\n",
    "\n",
    "    Args:\n",
    "        fold (pd.DataFrame): A single fold\n",
    "        input_length (int): How long each X_i should be\n",
    "        output_length (int): How long each y_i should be\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame]: A tuple of two dataframes (X_i, y_i)\n",
    "    \"\"\"\n",
    "\n",
    "    first_possible_start = 0\n",
    "    last_possible_start = len(fold) - (input_length + output_length) + 1\n",
    "    random_start = np.random.randint(first_possible_start, last_possible_start)\n",
    "    X_i = fold.iloc[random_start:random_start+input_length]\n",
    "    y_i = fold.iloc[random_start+input_length:\n",
    "                  random_start+input_length+output_length][TARGET]\n",
    "\n",
    "    return (X_i, y_i)\n",
    "\n",
    "def get_X_y(\n",
    "    fold:pd.DataFrame,\n",
    "    number_of_sequences:int,\n",
    "    input_length:int,\n",
    "    output_length:int) -> Tuple[np.array]:\n",
    "    \"\"\"Given a fold generate X and y based on the number of desired sequences\n",
    "    of the given input_length and output_length\n",
    "\n",
    "    Args:\n",
    "        fold (pd.DataFrame): Fold dataframe\n",
    "        number_of_sequences (int): The number of X_i and y_i pairs to include\n",
    "        input_length (int): Length of each X_i\n",
    "        output_length (int): Length of each y_i\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.array]: A tuple of numpy arrays (X, y)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(number_of_sequences):\n",
    "        (Xi, yi) = get_Xi_yi(fold, input_length, output_length)\n",
    "        X.append(Xi)\n",
    "        y.append(yi)\n",
    "\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load rental_data from local CSV...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandra/code/shoefer987/bike_sharing_demand/bikesharing/ml_logic/data.py:33: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(cache_path, header='infer' if data_has_header else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded, with shape (2804147, 10)\n"
     ]
    }
   ],
   "source": [
    "from bikesharing.interface.main import preprocess\n",
    "from bikesharing.ml_logic.data import get_raw_data\n",
    "from bikesharing.params import *\n",
    "\n",
    "query =f'''\n",
    "        SELECT *\n",
    "        FROM `{GCP_PROJECT}.{BQ_DATASET}.raw_data_mvg`\n",
    "    '''\n",
    "df = get_raw_data(GCP_PROJECT, query=query, cache_path=Path(f'{LOCAL_DATA_PATH}/raw/mvg_rentals_from_{START_YEAR}_to_{END_YEAR}.csv'))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bikesharing.ml_logic.data import get_polygons, get_weather_data\n",
    "from bikesharing.ml_logic.preprocessor import group_rental_data_by_hour, preprocess_features\n",
    "from bikesharing.ml_logic.encoders import encode_district_label, encode_temporal_features\n",
    "from bikesharing.ml_logic.feature_engineering import is_holiday, is_weekend, feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. drop cols\n",
    "rental_relavent_cols_df = df[['STARTTIME' , 'STARTLAT' , 'STARTLON']]\n",
    "\n",
    "# 3. clean(rm duplicates)\n",
    "rental_relavent_cols_df = rental_relavent_cols_df.drop_duplicates()\n",
    "\n",
    "# 4. encode y\n",
    "encoded_rental_df = encode_district_label(rental_relavent_cols_df , get_polygons())\n",
    "\n",
    "# 5. aggregate by hour\n",
    "aggregated_rental_df = group_rental_data_by_hour(encoded_rental_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_rental_df.to_csv(f'{LOCAL_DATA_PATH}/processed/aggregated_rental_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_rental_df = pd.read_csv(f'{LOCAL_DATA_PATH}/processed/aggregated_rental_df.csv')\n",
    "aggregated_rental_df.rent_date_hour = pd.to_datetime(aggregated_rental_df.rent_date_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load weather_data from local CSV...\u001b[0m\n",
      "âœ… Data loaded, with shape (35064, 6)\n"
     ]
    }
   ],
   "source": [
    "# 6. join with weather data\n",
    "weather_data_df = get_weather_data(cache_path=Path(f'{LOCAL_DATA_PATH}/raw/histotical_weather_data_{START_YEAR}_to_{END_YEAR}.csv'))\n",
    "weather_data_df['time'] = pd.to_datetime(weather_data_df['time'])\n",
    "merged_df = aggregated_rental_df.merge(weather_data_df, right_on='time' , left_on='rent_date_hour' , how='outer')\n",
    "merged_df['rent_date_hour'] = merged_df['time']\n",
    "merged_df = merged_df.sort_values(by='rent_date_hour').drop(columns=['time'])\n",
    "\n",
    "# 7. feature enginering & merge\n",
    "holidays = is_holiday(merged_df[['rent_date_hour']])\n",
    "merged_df = merged_df.merge(holidays , on='rent_date_hour' , how='inner')\n",
    "\n",
    "weekends = is_weekend(merged_df[['rent_date_hour']])\n",
    "merged_df = merged_df.merge(weekends , on='rent_date_hour' , how='inner')\n",
    "\n",
    "encoded_date = encode_temporal_features(merged_df[['rent_date_hour']])\n",
    "merged_df = merged_df.merge(encoded_date , on='rent_date_hour' , how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rent_date_hour</th>\n",
       "      <th>Altstadt-Lehel</th>\n",
       "      <th>Au - Haidhausen</th>\n",
       "      <th>Aubing-Lochhausen-Langwied</th>\n",
       "      <th>Berg am Laim</th>\n",
       "      <th>Bogenhausen</th>\n",
       "      <th>Feldmoching</th>\n",
       "      <th>Hadern</th>\n",
       "      <th>Harlaching</th>\n",
       "      <th>Hasenbergl-Lerchenau Ost</th>\n",
       "      <th>...</th>\n",
       "      <th>windspeed_10m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>2.012985e-01</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>2.012985e-01</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>2.012985e-01</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>2.012985e-01</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>2.012985e-01</td>\n",
       "      <td>0.97953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rent_date_hour  Altstadt-Lehel  Au - Haidhausen  \\\n",
       "0     2019-01-01 00:00:00             1.0              0.0   \n",
       "1     2019-01-01 01:00:00             0.0              0.0   \n",
       "2     2019-01-01 02:00:00             1.0              1.0   \n",
       "3     2019-01-01 03:00:00             0.0              4.0   \n",
       "4     2019-01-01 04:00:00             2.0              1.0   \n",
       "...                   ...             ...              ...   \n",
       "35059 2022-12-31 19:00:00             5.0              4.0   \n",
       "35060 2022-12-31 20:00:00             4.0              1.0   \n",
       "35061 2022-12-31 21:00:00             0.0              3.0   \n",
       "35062 2022-12-31 22:00:00             5.0              3.0   \n",
       "35063 2022-12-31 23:00:00             1.0              5.0   \n",
       "\n",
       "       Aubing-Lochhausen-Langwied  Berg am Laim  Bogenhausen  Feldmoching  \\\n",
       "0                             0.0           0.0          0.0          0.0   \n",
       "1                             0.0           0.0          2.0          0.0   \n",
       "2                             0.0           0.0          2.0          0.0   \n",
       "3                             0.0           0.0          0.0          0.0   \n",
       "4                             0.0           0.0          0.0          0.0   \n",
       "...                           ...           ...          ...          ...   \n",
       "35059                         0.0           1.0          1.0          0.0   \n",
       "35060                         0.0           0.0          1.0          0.0   \n",
       "35061                         0.0           0.0          1.0          0.0   \n",
       "35062                         0.0           0.0          5.0          0.0   \n",
       "35063                         0.0           0.0          1.0          0.0   \n",
       "\n",
       "       Hadern  Harlaching  Hasenbergl-Lerchenau Ost  ...  windspeed_10m  \\\n",
       "0         0.0         0.0                       0.0  ...            9.0   \n",
       "1         0.0         0.0                       0.0  ...            9.7   \n",
       "2         0.0         0.0                       0.0  ...           12.0   \n",
       "3         0.0         0.0                       0.0  ...           13.5   \n",
       "4         0.0         0.0                       0.0  ...           14.1   \n",
       "...       ...         ...                       ...  ...            ...   \n",
       "35059     1.0         0.0                       0.0  ...            8.0   \n",
       "35060     0.0         0.0                       0.0  ...            6.8   \n",
       "35061     0.0         0.0                       0.0  ...            7.2   \n",
       "35062     0.0         0.0                       0.0  ...            8.8   \n",
       "35063     0.0         0.0                       0.0  ...            6.8   \n",
       "\n",
       "       precipitation  is_holiday  is_weekend      hour_sin  hour_cos  \\\n",
       "0                0.2           1           0  2.588190e-01  0.965926   \n",
       "1                0.1           1           0  5.000000e-01  0.866025   \n",
       "2                0.2           1           0  7.071068e-01  0.707107   \n",
       "3                0.1           1           0  8.660254e-01  0.500000   \n",
       "4                0.0           1           0  9.659258e-01  0.258819   \n",
       "...              ...         ...         ...           ...       ...   \n",
       "35059            0.0           0           1 -8.660254e-01  0.500000   \n",
       "35060            0.0           0           1 -7.071068e-01  0.707107   \n",
       "35061            0.0           0           1 -5.000000e-01  0.866025   \n",
       "35062            0.0           0           1 -2.588190e-01  0.965926   \n",
       "35063            0.0           0           1 -2.449294e-16  1.000000   \n",
       "\n",
       "          month_sin  month_cos       day_sin  day_cos  \n",
       "0      5.000000e-01   0.866025  2.012985e-01  0.97953  \n",
       "1      5.000000e-01   0.866025  2.012985e-01  0.97953  \n",
       "2      5.000000e-01   0.866025  2.012985e-01  0.97953  \n",
       "3      5.000000e-01   0.866025  2.012985e-01  0.97953  \n",
       "4      5.000000e-01   0.866025  2.012985e-01  0.97953  \n",
       "...             ...        ...           ...      ...  \n",
       "35059 -2.449294e-16   1.000000 -2.449294e-16  1.00000  \n",
       "35060 -2.449294e-16   1.000000 -2.449294e-16  1.00000  \n",
       "35061 -2.449294e-16   1.000000 -2.449294e-16  1.00000  \n",
       "35062 -2.449294e-16   1.000000 -2.449294e-16  1.00000  \n",
       "35063 -2.449294e-16   1.000000 -2.449294e-16  1.00000  \n",
       "\n",
       "[35064 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def preprocess_features(df: pd.DataFrame):\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    def create_preprocessor() -> ColumnTransformer:\n",
    "\n",
    "        # SCALE PIPE\n",
    "        scaler_pipe = Pipeline([\n",
    "            ('scaler', MinMaxScaler())\n",
    "        ])\n",
    "\n",
    "        return scaler_pipe\n",
    "\n",
    "    X = df[['temperature_2m', 'relativehumidity_2m', 'apparent_temperature',\n",
    "       'windspeed_10m', 'precipitation','hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'day_sin', 'day_cos']]\n",
    "\n",
    "    preprocessor = create_preprocessor()\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "    return pd.concat([pd.DataFrame(X_processed) , df[['is_holiday', 'is_weekend']]] , axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. feature selection\n",
    "districts = ['Altstadt-Lehel', 'Au - Haidhausen',\n",
    "       'Aubing-Lochhausen-Langwied', 'Berg am Laim', 'Bogenhausen',\n",
    "       'Feldmoching', 'Hadern', 'Harlaching', 'Hasenbergl-Lerchenau Ost',\n",
    "       'Laim', 'Lochhausen', 'Ludwigsvorstadt-Isarvorstadt', 'Maxvorstadt',\n",
    "       'Milbertshofen-Am Hart', 'Moosach', 'Neuhausen-Nymphenburg',\n",
    "       'Obergiesing', 'Obermenzing', 'Obersendling', 'Pasing',\n",
    "       'Pasing-Obermenzing', 'Ramersdorf-Perlach', 'Schwabing-Freimann',\n",
    "       'Schwabing-West', 'SchwanthalerhÃ¶he', 'Sendling', 'Sendling-Westpark',\n",
    "       'SÃ¼dgiesing', 'Thalkirchen', 'Trudering', 'Trudering-Riem',\n",
    "       'Untergiesing', 'Untergiesing-Harlaching', 'Untermenzing-Allach']\n",
    "\n",
    "    \n",
    "X = merged_df.drop(columns=districts)\n",
    "y = merged_df[districts].fillna(0)\n",
    "\n",
    "features = ['temperature_2m', 'relativehumidity_2m', 'apparent_temperature',\n",
    "       'windspeed_10m', 'precipitation', 'is_holiday', 'is_weekend',\n",
    "       'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'day_sin', 'day_cos']\n",
    "\n",
    "selected_merged_df = feature_selection(X , features)\n",
    "\n",
    "# 9. preproc-pipeline (Keep date_time for RNN)\n",
    "X_processed = preprocess_features(selected_merged_df)\n",
    "\n",
    "cache_path_X_preproc=Path(f'{LOCAL_DATA_PATH}/processed/X_processed_from_{START_YEAR}_to_{END_YEAR}.csv')\n",
    "cache_path_y_preproc=Path(f'{LOCAL_DATA_PATH}/processed/y_processed_from_{START_YEAR}_to_{END_YEAR}.csv')\n",
    "\n",
    "X_processed.columns = features\n",
    "X_processed.to_csv(cache_path_X_preproc , header=True , index=False)\n",
    "y.to_csv(cache_path_y_preproc , header=True , index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relativehumidity_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>windspeed_10m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.355408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.342007</td>\n",
       "      <td>0.227848</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.629410</td>\n",
       "      <td>0.982963</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.600779</td>\n",
       "      <td>0.989739</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357616</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.340149</td>\n",
       "      <td>0.245570</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.600779</td>\n",
       "      <td>0.989739</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.359823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336431</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.600779</td>\n",
       "      <td>0.989739</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.359823</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.332714</td>\n",
       "      <td>0.341772</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.600779</td>\n",
       "      <td>0.989739</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.359823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.332714</td>\n",
       "      <td>0.356962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982963</td>\n",
       "      <td>0.629410</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.600779</td>\n",
       "      <td>0.989739</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature_2m  relativehumidity_2m  apparent_temperature  windspeed_10m  \\\n",
       "0        0.355408             1.000000              0.342007       0.227848   \n",
       "1        0.357616             0.987013              0.340149       0.245570   \n",
       "2        0.359823             1.000000              0.336431       0.303797   \n",
       "3        0.359823             0.987013              0.332714       0.341772   \n",
       "4        0.359823             1.000000              0.332714       0.356962   \n",
       "\n",
       "   precipitation  is_holiday  is_weekend  hour_sin  hour_cos  month_sin  \\\n",
       "0       0.017391    0.629410    0.982963      0.75  0.933013   0.600779   \n",
       "1       0.008696    0.750000    0.933013      0.75  0.933013   0.600779   \n",
       "2       0.017391    0.853553    0.853553      0.75  0.933013   0.600779   \n",
       "3       0.008696    0.933013    0.750000      0.75  0.933013   0.600779   \n",
       "4       0.000000    0.982963    0.629410      0.75  0.933013   0.600779   \n",
       "\n",
       "   month_cos  day_sin  day_cos  \n",
       "0   0.989739        1        0  \n",
       "1   0.989739        1        0  \n",
       "2   0.989739        1        0  \n",
       "3   0.989739        1        0  \n",
       "4   0.989739        1        0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altstadt-Lehel</th>\n",
       "      <th>Au - Haidhausen</th>\n",
       "      <th>Aubing-Lochhausen-Langwied</th>\n",
       "      <th>Berg am Laim</th>\n",
       "      <th>Bogenhausen</th>\n",
       "      <th>Feldmoching</th>\n",
       "      <th>Hadern</th>\n",
       "      <th>Harlaching</th>\n",
       "      <th>Hasenbergl-Lerchenau Ost</th>\n",
       "      <th>Laim</th>\n",
       "      <th>...</th>\n",
       "      <th>SchwanthalerhÃ¶he</th>\n",
       "      <th>Sendling</th>\n",
       "      <th>Sendling-Westpark</th>\n",
       "      <th>SÃ¼dgiesing</th>\n",
       "      <th>Thalkirchen</th>\n",
       "      <th>Trudering</th>\n",
       "      <th>Trudering-Riem</th>\n",
       "      <th>Untergiesing</th>\n",
       "      <th>Untergiesing-Harlaching</th>\n",
       "      <th>Untermenzing-Allach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Altstadt-Lehel  Au - Haidhausen  Aubing-Lochhausen-Langwied  Berg am Laim  \\\n",
       "0             1.0              0.0                         0.0           0.0   \n",
       "1             0.0              0.0                         0.0           0.0   \n",
       "2             1.0              1.0                         0.0           0.0   \n",
       "3             0.0              4.0                         0.0           0.0   \n",
       "4             2.0              1.0                         0.0           0.0   \n",
       "\n",
       "   Bogenhausen  Feldmoching  Hadern  Harlaching  Hasenbergl-Lerchenau Ost  \\\n",
       "0          0.0          0.0     0.0         0.0                       0.0   \n",
       "1          2.0          0.0     0.0         0.0                       0.0   \n",
       "2          2.0          0.0     0.0         0.0                       0.0   \n",
       "3          0.0          0.0     0.0         0.0                       0.0   \n",
       "4          0.0          0.0     0.0         0.0                       0.0   \n",
       "\n",
       "   Laim  ...  SchwanthalerhÃ¶he  Sendling  Sendling-Westpark  SÃ¼dgiesing  \\\n",
       "0   0.0  ...               0.0       0.0                2.0         0.0   \n",
       "1   0.0  ...               0.0       2.0                0.0         0.0   \n",
       "2   3.0  ...               0.0       5.0                0.0         0.0   \n",
       "3   1.0  ...               3.0       0.0                0.0         0.0   \n",
       "4   1.0  ...               1.0       0.0                1.0         0.0   \n",
       "\n",
       "   Thalkirchen  Trudering  Trudering-Riem  Untergiesing  \\\n",
       "0          0.0        0.0             0.0           0.0   \n",
       "1          0.0        0.0             0.0           1.0   \n",
       "2          0.0        0.0             0.0           1.0   \n",
       "3          0.0        0.0             0.0           1.0   \n",
       "4          0.0        0.0             0.0           0.0   \n",
       "\n",
       "   Untergiesing-Harlaching  Untermenzing-Allach  \n",
       "0                      0.0                  0.0  \n",
       "1                      1.0                  0.0  \n",
       "2                      1.0                  0.0  \n",
       "3                      1.0                  0.0  \n",
       "4                      0.0                  0.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35064, 47)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([X_processed, y], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Altstadt-Lehel', 'Au - Haidhausen', 'Aubing-Lochhausen-Langwied',\n",
       "       'Berg am Laim', 'Bogenhausen', 'Feldmoching', 'Hadern', 'Harlaching',\n",
       "       'Hasenbergl-Lerchenau Ost', 'Laim', 'Lochhausen',\n",
       "       'Ludwigsvorstadt-Isarvorstadt', 'Maxvorstadt', 'Milbertshofen-Am Hart',\n",
       "       'Moosach', 'Neuhausen-Nymphenburg', 'Obergiesing', 'Obermenzing',\n",
       "       'Obersendling', 'Pasing', 'Pasing-Obermenzing', 'Ramersdorf-Perlach',\n",
       "       'Schwabing-Freimann', 'Schwabing-West', 'SchwanthalerhÃ¶he', 'Sendling',\n",
       "       'Sendling-Westpark', 'SÃ¼dgiesing', 'Thalkirchen', 'Trudering',\n",
       "       'Trudering-Riem', 'Untergiesing', 'Untergiesing-Harlaching',\n",
       "       'Untermenzing-Allach'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "districts = y.columns\n",
    "districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_LENGTH = 17520\n",
    "FOLD_STRIDE = 2184\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "INPUT_LENGTH = 336 # 24 h * 14 d\n",
    "OUTPUT_LENGTH = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = get_folds(data, FOLD_LENGTH, FOLD_STRIDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fold_train, fold_test) = train_test_split(folds[0], TRAIN_TEST_RATIO, INPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['temperature_2m', 'relativehumidity_2m', 'apparent_temperature',\n",
       "       'windspeed_10m', 'precipitation', 'is_holiday', 'is_weekend',\n",
       "       'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'day_sin', 'day_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = districts\n",
    "N_TARGETS = len(districts)\n",
    "N_FEATURES = len(X_processed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_i, y_train_i = get_Xi_yi(fold_train, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "X_test_i, y_test_i = get_Xi_yi(fold_test, INPUT_LENGTH, OUTPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relativehumidity_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>windspeed_10m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>...</th>\n",
       "      <th>SchwanthalerhÃ¶he</th>\n",
       "      <th>Sendling</th>\n",
       "      <th>Sendling-Westpark</th>\n",
       "      <th>SÃ¼dgiesing</th>\n",
       "      <th>Thalkirchen</th>\n",
       "      <th>Trudering</th>\n",
       "      <th>Trudering-Riem</th>\n",
       "      <th>Untergiesing</th>\n",
       "      <th>Untergiesing-Harlaching</th>\n",
       "      <th>Untermenzing-Allach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>0.567329</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.544610</td>\n",
       "      <td>0.220253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982963</td>\n",
       "      <td>0.370590</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.173895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>0.626932</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.592937</td>\n",
       "      <td>0.248101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.173895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>0.657837</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.624535</td>\n",
       "      <td>0.245570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.146447</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.173895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>0.684327</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.665428</td>\n",
       "      <td>0.215190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.173895</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.698885</td>\n",
       "      <td>0.179747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629410</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.173895</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>0.545254</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.555762</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.697431</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>0.536424</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.544610</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.697431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>0.527594</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.535316</td>\n",
       "      <td>0.055696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.697431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>0.527594</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.533457</td>\n",
       "      <td>0.058228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982963</td>\n",
       "      <td>0.629410</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.697431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>0.576159</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.581784</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.697431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      temperature_2m  relativehumidity_2m  apparent_temperature  \\\n",
       "3318        0.567329             0.688312              0.544610   \n",
       "3319        0.626932             0.545455              0.592937   \n",
       "3320        0.657837             0.493506              0.624535   \n",
       "3321        0.684327             0.441558              0.665428   \n",
       "3322        0.708609             0.389610              0.698885   \n",
       "...              ...                  ...                   ...   \n",
       "3649        0.545254             0.922078              0.555762   \n",
       "3650        0.536424             0.922078              0.544610   \n",
       "3651        0.527594             0.909091              0.535316   \n",
       "3652        0.527594             0.909091              0.533457   \n",
       "3653        0.576159             0.922078              0.581784   \n",
       "\n",
       "      windspeed_10m  precipitation  is_holiday  is_weekend  hour_sin  \\\n",
       "3318       0.220253            0.0    0.982963    0.370590      0.75   \n",
       "3319       0.248101            0.0    0.933013    0.250000      0.75   \n",
       "3320       0.245570            0.0    0.853553    0.146447      0.75   \n",
       "3321       0.215190            0.0    0.750000    0.066987      0.75   \n",
       "3322       0.179747            0.0    0.629410    0.017037      0.75   \n",
       "...             ...            ...         ...         ...       ...   \n",
       "3649       0.027848            0.0    0.750000    0.933013      0.50   \n",
       "3650       0.037975            0.0    0.853553    0.853553      0.50   \n",
       "3651       0.055696            0.0    0.933013    0.750000      0.50   \n",
       "3652       0.058228            0.0    0.982963    0.629410      0.50   \n",
       "3653       0.098734            0.0    1.000000    0.500000      0.50   \n",
       "\n",
       "      hour_cos  month_sin  ...  SchwanthalerhÃ¶he  Sendling  Sendling-Westpark  \\\n",
       "3318  0.066987   0.173895  ...               0.0       2.0                0.0   \n",
       "3319  0.066987   0.173895  ...               0.0       2.0                0.0   \n",
       "3320  0.066987   0.173895  ...               0.0       3.0                0.0   \n",
       "3321  0.066987   0.173895  ...               2.0       1.0                1.0   \n",
       "3322  0.066987   0.173895  ...               2.0      12.0                1.0   \n",
       "...        ...        ...  ...               ...       ...                ...   \n",
       "3649  0.000000   0.697431  ...               1.0       1.0                1.0   \n",
       "3650  0.000000   0.697431  ...               0.0       0.0                0.0   \n",
       "3651  0.000000   0.697431  ...               0.0       1.0                3.0   \n",
       "3652  0.000000   0.697431  ...               0.0       0.0                0.0   \n",
       "3653  0.000000   0.697431  ...               0.0       2.0                0.0   \n",
       "\n",
       "      SÃ¼dgiesing  Thalkirchen  Trudering  Trudering-Riem  Untergiesing  \\\n",
       "3318         0.0          0.0        0.0             0.0           2.0   \n",
       "3319         0.0          0.0        0.0             0.0           0.0   \n",
       "3320         0.0          0.0        0.0             0.0           1.0   \n",
       "3321         0.0          0.0        2.0             2.0           2.0   \n",
       "3322         0.0          1.0        0.0             0.0           1.0   \n",
       "...          ...          ...        ...             ...           ...   \n",
       "3649         0.0          0.0        1.0             1.0           1.0   \n",
       "3650         0.0          1.0        0.0             0.0           1.0   \n",
       "3651         0.0          2.0        0.0             0.0           0.0   \n",
       "3652         0.0          0.0        0.0             0.0           1.0   \n",
       "3653         0.0          0.0        0.0             0.0           0.0   \n",
       "\n",
       "      Untergiesing-Harlaching  Untermenzing-Allach  \n",
       "3318                      2.0                  0.0  \n",
       "3319                      0.0                  0.0  \n",
       "3320                      1.0                  0.0  \n",
       "3321                      2.0                  0.0  \n",
       "3322                      1.0                  1.0  \n",
       "...                       ...                  ...  \n",
       "3649                      1.0                  0.0  \n",
       "3650                      1.0                  0.0  \n",
       "3651                      0.0                  0.0  \n",
       "3652                      1.0                  0.0  \n",
       "3653                      0.0                  0.0  \n",
       "\n",
       "[336 rows x 47 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = 8000 # number_of_sequences_train\n",
    "N_TEST =  2000 # number_of_sequences_test\n",
    "\n",
    "X_train, y_train = get_X_y(fold_train, N_TRAIN, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "X_test, y_test = get_X_y(fold_test, N_TEST, INPUT_LENGTH, OUTPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8000, 336, 47), y_train: (8000, 24, 34)\n",
      "X_test: (2000, 336, 47), y_test: (2000, 24, 34)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29580574, 0.7012987 , 0.23234201, 0.6       , 0.        ,\n",
       "       1.        , 0.5       , 0.9330127 , 0.75      , 0.92486744,\n",
       "       0.76387627, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       2.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 2., 1., 0., 0., 0., 1., 0., 0., 0., 2., 2., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 09:01:07.465021: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-09 09:01:07.504687: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-09 09:01:07.704419: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-09 09:01:07.705648: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-09 09:01:08.815353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers, metrics\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(X_train, y_train):\n",
    "    # E1D1\n",
    "    # n_features ==> no of features at each timestep in the data.\n",
    "    #\n",
    "    encoder_inputs = layers.Input(shape=X_train[0].shape)\n",
    "    encoder_l1 = layers.LSTM(100, return_state=True)\n",
    "    encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "\n",
    "    encoder_states1 = encoder_outputs1[1:]\n",
    "\n",
    "    #\n",
    "    decoder_inputs = layers.RepeatVector(OUTPUT_LENGTH)(encoder_outputs1[0])\n",
    "\n",
    "    #\n",
    "    decoder_l1 = layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "    decoder_outputs1 = layers.TimeDistributed(layers.Dense(N_FEATURES))(decoder_l1)\n",
    "\n",
    "    #\n",
    "    model_e1d1 = models.Model(encoder_inputs,decoder_outputs1)\n",
    "    \n",
    "    # 2 - Compiler\n",
    "    # ======================    \n",
    "    adam = optimizers.Adam(learning_rate=0.02)    \n",
    "    model_e1d1.compile(loss='mse', optimizer=adam, metrics=[\"mae\"])\n",
    "    \n",
    "    return model_e1d1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(X_train, y_train):\n",
    "        \n",
    "    # 0 - Normalization\n",
    "    # ======================    \n",
    "    normalizer = Normalization()\n",
    "    normalizer.adapt(X_train)\n",
    "    \n",
    "    # 1 - RNN architecture\n",
    "    # ======================    \n",
    "    model = models.Sequential()\n",
    "    ## 1.0 - All the rows will be standardized through the already adapted normalization layer\n",
    "    model.add(normalizer)\n",
    "    ## 1.1 - Recurrent Layer\n",
    "    model.add(layers.LSTM(64, \n",
    "                          activation='tanh', \n",
    "                          return_sequences = True,\n",
    "                          kernel_regularizer=L1L2(l1=0.05, l2=0.05),\n",
    "                          ))\n",
    "    ## 1.2 - Predictive Dense Layers\n",
    "    output_length = y_train.shape[1:]\n",
    "    model.add(layers.TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "    #model.add(layers.Dense(output_length, activation='linear'))\n",
    "\n",
    "    # 2 - Compiler\n",
    "    # ======================    \n",
    "    adam = optimizers.Adam(learning_rate=0.02)    \n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[\"mae\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 336, 47)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  [(None, 100),        59200       ['input_4[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector_3 (RepeatVector)  (None, 24, 100)     0           ['lstm_6[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  (None, 24, 100)      80400       ['repeat_vector_3[0][0]',        \n",
      "                                                                  'lstm_6[0][1]',                 \n",
      "                                                                  'lstm_6[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 24, 13)      1313        ['lstm_7[0][0]']                 \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 140,913\n",
      "Trainable params: 140,913\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 09:05:14.287112: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 09:05:14.288209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 09:05:14.290647: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-09 09:05:14.432460: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 09:05:14.433615: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 09:05:14.434669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model = init_model(X_train, y_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "    # --- LOSS: MSE --- \n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('MSE')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    # --- METRICS:MAE ---\n",
    "    \n",
    "    ax[1].plot(history.history['mae'])\n",
    "    ax[1].plot(history.history['val_mae'])\n",
    "    ax[1].set_title('MAE')\n",
    "    ax[1].set_ylabel('MAE')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "                        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def fit_model(model: keras.Model, verbose=1) -> Tuple[keras.Model, dict]:\n",
    "\n",
    "    es = EarlyStopping(monitor = \"val_loss\",\n",
    "                      patience = 3,\n",
    "                      mode = \"min\",\n",
    "                      restore_best_weights = True)\n",
    "\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split = 0.3,\n",
    "                        shuffle = False,\n",
    "                        batch_size = 32,\n",
    "                        epochs = 50,\n",
    "                        callbacks = [es],\n",
    "                        verbose = verbose)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 336, 47)]    0           []                               \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)                  [(None, 100),        59200       ['input_5[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector_4 (RepeatVector)  (None, 24, 100)     0           ['lstm_8[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)                  (None, 24, 100)      80400       ['repeat_vector_4[0][0]',        \n",
      "                                                                  'lstm_8[0][1]',                 \n",
      "                                                                  'lstm_8[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDistri  (None, 24, 13)      1313        ['lstm_9[0][0]']                 \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 140,913\n",
      "Trainable params: 140,913\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 09:05:27.646459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 09:05:27.648653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 09:05:27.649892: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-09 09:05:27.778511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 09:05:27.779623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 09:05:27.780623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 09:05:28.524085: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 09:05:28.528611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 09:05:28.531614: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-09 09:05:28.699189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-09 09:05:28.700633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-09 09:05:28.701543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/losses.py\", line 1470, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 13 and 34 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_4/time_distributed_4/Reshape_1, IteratorGetNext:1)' with input shapes: [32,24,13], [32,24,34].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[1;32m      7\u001b[0m \u001b[39m# 2 - Training\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# ====================================\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model, history \u001b[39m=\u001b[39m fit_model(model)\n",
      "Cell \u001b[0;32mIn[54], line 12\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(model, verbose)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_model\u001b[39m(model: keras\u001b[39m.\u001b[39mModel, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[keras\u001b[39m.\u001b[39mModel, \u001b[39mdict\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     es \u001b[39m=\u001b[39m EarlyStopping(monitor \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m                       patience \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m,\n\u001b[1;32m      8\u001b[0m                       mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m                       restore_best_weights \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 12\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train,\n\u001b[1;32m     13\u001b[0m                         validation_split \u001b[39m=\u001b[39;49m \u001b[39m0.3\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m                         shuffle \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     15\u001b[0m                         batch_size \u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m                         epochs \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m                         callbacks \u001b[39m=\u001b[39;49m [es],\n\u001b[1;32m     18\u001b[0m                         verbose \u001b[39m=\u001b[39;49m verbose)\n\u001b[1;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file089lhnvu.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/sandra/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/keras/losses.py\", line 1470, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 13 and 34 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_4/time_distributed_4/Reshape_1, IteratorGetNext:1)' with input shapes: [32,24,13], [32,24,34].\n"
     ]
    }
   ],
   "source": [
    "# 1 - Initialising the RNN model\n",
    "# ====================================\n",
    "\n",
    "model = init_model(X_train, y_train)\n",
    "model.summary()\n",
    "\n",
    "# 2 - Training\n",
    "# ====================================\n",
    "model, history = fit_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bike_sharing_demand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
