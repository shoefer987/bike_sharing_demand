{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bikesharing.ml_logic.data import get_raw_data ,get_weather_data ,get_polygons\n",
    "from bikesharing.params import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove duplicates\n",
    "- Deal with missing values\n",
    "- Scale the features\n",
    "- Encode features\n",
    "- Perform cyclical engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23698/1700516227.py:4: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'../raw_data/MVG_Rad_Fahrten_{year}.csv', sep=';')\n",
      "/tmp/ipykernel_23698/1700516227.py:4: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'../raw_data/MVG_Rad_Fahrten_{year}.csv', sep=';')\n",
      "/tmp/ipykernel_23698/1700516227.py:4: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'../raw_data/MVG_Rad_Fahrten_{year}.csv', sep=';')\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "meta = {'years':[], 'n_columns':[], 'n_rows':[]}\n",
    "for year in range(2019,2023,1):\n",
    "    df = pd.read_csv(f'../raw_data/MVG_Rad_Fahrten_{year}.csv', sep=';')\n",
    "    cols = [col.strip() for col in df.columns]\n",
    "    df.columns = cols\n",
    "    dfs.append(df)\n",
    "    meta['years'].append(year)\n",
    "    meta['n_columns'].append(df.shape[1])\n",
    "    meta['n_rows'].append(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753678, 11)\n",
      "(721752, 11)\n",
      "(619573, 11)\n",
      "(709144, 11)\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_df(df):\n",
    "  #vstrip column names\n",
    "  cols = [col.strip() for col in df.columns]\n",
    "  df.columns = cols\n",
    "\n",
    "  # remove column 'Row'\n",
    "  if 'Row' in df.columns:\n",
    "    df.drop(columns='Row', inplace=True)\n",
    "\n",
    "  # select relevant columns only\n",
    "  #df = df[['STARTTIME', 'STARTLAT', 'STARTLON', 'RENTAL_IS_STATION']].copy()\n",
    "  \n",
    "  # make string replacements values\n",
    "  df_obj = df.select_dtypes(include='object')\n",
    "  df[df_obj.columns] = df_obj.applymap(lambda x: x.strip().replace(',', '.') if isinstance(x, str) else x)\n",
    "\n",
    "  # handle datetime\n",
    "  df.STARTTIME = pd.to_datetime(df.STARTTIME)\n",
    "\n",
    "  # handle numeric columns\n",
    "  df.replace('NULL', np.NAN, inplace=True)\n",
    "  df.replace('', np.NAN, inplace=True)\n",
    "  df[['STARTLAT', 'STARTLON', 'RENTAL_IS_STATION','ENDLAT', 'ENDLON', 'RETURN_IS_STATION']] = df[['STARTLAT', 'STARTLON', 'RENTAL_IS_STATION','ENDLAT', 'ENDLON', 'RETURN_IS_STATION']].astype(np.float32)\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m pre_process_df(data)\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mpre_process_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# select relevant columns only\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m#df = df[['STARTTIME', 'STARTLAT', 'STARTLON', 'RENTAL_IS_STATION']].copy()\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[39m# make string replacements values\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df_obj \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mselect_dtypes(include\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m df[df_obj\u001b[39m.\u001b[39mcolumns] \u001b[39m=\u001b[39m df_obj\u001b[39m.\u001b[39;49mapplymap(\u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mstrip()\u001b[39m.\u001b[39;49mreplace(\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(x, \u001b[39mstr\u001b[39;49m) \u001b[39melse\u001b[39;49;00m x)\n\u001b[1;32m     17\u001b[0m \u001b[39m# handle datetime\u001b[39;00m\n\u001b[1;32m     18\u001b[0m df\u001b[39m.\u001b[39mSTARTTIME \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39mSTARTTIME)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/frame.py:9508\u001b[0m, in \u001b[0;36mDataFrame.applymap\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m   9505\u001b[0m         \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(x, func, ignore_na\u001b[39m=\u001b[39mignore_na)\n\u001b[1;32m   9506\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(x\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values, func, ignore_na\u001b[39m=\u001b[39mignore_na)\n\u001b[0;32m-> 9508\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(infer)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mapplymap\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/core/frame.py:9506\u001b[0m, in \u001b[0;36mDataFrame.applymap.<locals>.infer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   9504\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mempty:\n\u001b[1;32m   9505\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(x, func, ignore_na\u001b[39m=\u001b[39mignore_na)\n\u001b[0;32m-> 9506\u001b[0m \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(x\u001b[39m.\u001b[39;49mastype(\u001b[39mobject\u001b[39;49m)\u001b[39m.\u001b[39;49m_values, func, ignore_na\u001b[39m=\u001b[39;49mignore_na)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/bike_sharing_demand/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mpre_process_df.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# select relevant columns only\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m#df = df[['STARTTIME', 'STARTLAT', 'STARTLON', 'RENTAL_IS_STATION']].copy()\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[39m# make string replacements values\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df_obj \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mselect_dtypes(include\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m df[df_obj\u001b[39m.\u001b[39mcolumns] \u001b[39m=\u001b[39m df_obj\u001b[39m.\u001b[39mapplymap(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49mstrip()\u001b[39m.\u001b[39;49mreplace(\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m x)\n\u001b[1;32m     17\u001b[0m \u001b[39m# handle datetime\u001b[39;00m\n\u001b[1;32m     18\u001b[0m df\u001b[39m.\u001b[39mSTARTTIME \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39mSTARTTIME)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = pre_process_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_bq(\n",
    "        data: pd.DataFrame,\n",
    "        gcp_project:str,\n",
    "        bq_dataset:str,\n",
    "        table: str,\n",
    "        truncate: bool\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    - Save the DataFrame to BigQuery\n",
    "    - Empty the table beforehand if `truncate` is True, append otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(data, pd.DataFrame)\n",
    "    full_table_name = f\"{gcp_project}.{bq_dataset}.{table}\"\n",
    "\n",
    "    #print(Fore.BLUE + f\"\\nSave data to BigQuery @ {full_table_name}...:\" + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "    # reset column names\n",
    "    data.columns = [f'_{col}' if isinstance(col, int) else col for col in data.columns]\n",
    "\n",
    "    # Load data onto full_table_name\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    write_mode = \"WRITE_TRUNCATE\" if truncate else \"WRITE_APPEND\"\n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=write_mode)\n",
    "\n",
    "    job = client.load_table_from_dataframe(data, full_table_name, job_config=job_config)\n",
    "\n",
    "    # ðŸŽ¯ HINT for \"*** TypeError: expected bytes, int found\":\n",
    "    # After preprocessing the data, your original column names are gone (print it to check),\n",
    "    # so ensure that your column names are *strings* that start with either\n",
    "    # a *letter* or an *underscore*, as BQ does not accept anything else\n",
    "\n",
    "    print(f\"âœ… Data saved to bigquery, with shape {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2804147 entries, 0 to 709143\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   STARTTIME            datetime64[ns]\n",
      " 1   ENDTIME              object        \n",
      " 2   STARTLAT             float32       \n",
      " 3   STARTLON             float32       \n",
      " 4   ENDLAT               float32       \n",
      " 5   ENDLON               float32       \n",
      " 6   RENTAL_IS_STATION    float32       \n",
      " 7   RENTAL_STATION_NAME  object        \n",
      " 8   RETURN_IS_STATION    float32       \n",
      " 9   RETURN_STATION_NAME  object        \n",
      "dtypes: datetime64[ns](1), float32(6), object(3)\n",
      "memory usage: 171.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data saved to bigquery, with shape (2804147, 10)\n"
     ]
    }
   ],
   "source": [
    "load_data_to_bq(\n",
    "        data=data,\n",
    "        gcp_project=os.environ.get(\"GCP_PROJECT\"),\n",
    "        bq_dataset=os.environ.get(\"BQ_DATASET\"),\n",
    "        table='raw_data_mvg',\n",
    "        truncate=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =f'''\n",
    "        SELECT *\n",
    "        FROM `{GCP_PROJECT}.{BQ_DATASET}.raw_data_mvg`\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load data from local CSV...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/code/shoefer987/bike_sharing_demand/bikesharing/ml_logic/data.py:43: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(cache_path, header='infer' if data_has_header else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded, with shape (2804147, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STARTTIME</th>\n",
       "      <th>ENDTIME</th>\n",
       "      <th>STARTLAT</th>\n",
       "      <th>STARTLON</th>\n",
       "      <th>ENDLAT</th>\n",
       "      <th>ENDLON</th>\n",
       "      <th>RENTAL_IS_STATION</th>\n",
       "      <th>RENTAL_STATION_NAME</th>\n",
       "      <th>RETURN_IS_STATION</th>\n",
       "      <th>RETURN_STATION_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 02:47:00</td>\n",
       "      <td>2019-01-01 02:54</td>\n",
       "      <td>48.088402</td>\n",
       "      <td>11.48060</td>\n",
       "      <td>48.087601</td>\n",
       "      <td>11.46165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FÃ¼rstenried West</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Am Sportpark Neuried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>2019-01-01 04:22</td>\n",
       "      <td>48.105709</td>\n",
       "      <td>11.41446</td>\n",
       "      <td>48.092430</td>\n",
       "      <td>11.45626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bahnhof Ost Planegg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Kraillinger Weg Neuried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 15:29:00</td>\n",
       "      <td>2019-01-01 15:32</td>\n",
       "      <td>48.155258</td>\n",
       "      <td>11.54012</td>\n",
       "      <td>48.152908</td>\n",
       "      <td>11.53310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AlbrechtstraÃŸe</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rotkreuzplatz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 15:32:00</td>\n",
       "      <td>2019-01-01 15:40</td>\n",
       "      <td>48.179588</td>\n",
       "      <td>11.58906</td>\n",
       "      <td>48.161991</td>\n",
       "      <td>11.58654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Anni-Albers-StraÃŸe</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MÃ¼nchner Freiheit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 15:45:00</td>\n",
       "      <td>2019-01-01 15:58</td>\n",
       "      <td>48.155231</td>\n",
       "      <td>11.57548</td>\n",
       "      <td>48.139400</td>\n",
       "      <td>11.58888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NordendstraÃŸe</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lehel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804142</th>\n",
       "      <td>2022-12-17 19:39:00</td>\n",
       "      <td>2022-12-17 19:42</td>\n",
       "      <td>48.161991</td>\n",
       "      <td>11.58654</td>\n",
       "      <td>48.161251</td>\n",
       "      <td>11.59206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MÃ¼nchner Freiheit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804143</th>\n",
       "      <td>2022-12-20 19:40:00</td>\n",
       "      <td>2022-12-20 19:48</td>\n",
       "      <td>48.161991</td>\n",
       "      <td>11.58654</td>\n",
       "      <td>48.162029</td>\n",
       "      <td>11.56343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MÃ¼nchner Freiheit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804144</th>\n",
       "      <td>2022-12-22 17:03:00</td>\n",
       "      <td>2022-12-22 17:15</td>\n",
       "      <td>48.161991</td>\n",
       "      <td>11.58654</td>\n",
       "      <td>48.180382</td>\n",
       "      <td>11.59943</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MÃ¼nchner Freiheit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804145</th>\n",
       "      <td>2022-12-28 09:42:00</td>\n",
       "      <td>2022-12-28 09:58</td>\n",
       "      <td>48.161991</td>\n",
       "      <td>11.58654</td>\n",
       "      <td>48.162739</td>\n",
       "      <td>11.57268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MÃ¼nchner Freiheit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804146</th>\n",
       "      <td>2022-12-31 10:01:00</td>\n",
       "      <td>2022-12-31 10:19</td>\n",
       "      <td>48.161991</td>\n",
       "      <td>11.58654</td>\n",
       "      <td>48.157879</td>\n",
       "      <td>11.57722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MÃ¼nchner Freiheit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2804147 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   STARTTIME           ENDTIME   STARTLAT  STARTLON  \\\n",
       "0        2019-01-01 02:47:00  2019-01-01 02:54  48.088402  11.48060   \n",
       "1        2019-01-01 04:00:00  2019-01-01 04:22  48.105709  11.41446   \n",
       "2        2019-01-01 15:29:00  2019-01-01 15:32  48.155258  11.54012   \n",
       "3        2019-01-01 15:32:00  2019-01-01 15:40  48.179588  11.58906   \n",
       "4        2019-01-01 15:45:00  2019-01-01 15:58  48.155231  11.57548   \n",
       "...                      ...               ...        ...       ...   \n",
       "2804142  2022-12-17 19:39:00  2022-12-17 19:42  48.161991  11.58654   \n",
       "2804143  2022-12-20 19:40:00  2022-12-20 19:48  48.161991  11.58654   \n",
       "2804144  2022-12-22 17:03:00  2022-12-22 17:15  48.161991  11.58654   \n",
       "2804145  2022-12-28 09:42:00  2022-12-28 09:58  48.161991  11.58654   \n",
       "2804146  2022-12-31 10:01:00  2022-12-31 10:19  48.161991  11.58654   \n",
       "\n",
       "            ENDLAT    ENDLON  RENTAL_IS_STATION  RENTAL_STATION_NAME  \\\n",
       "0        48.087601  11.46165                1.0     FÃ¼rstenried West   \n",
       "1        48.092430  11.45626                1.0  Bahnhof Ost Planegg   \n",
       "2        48.152908  11.53310                1.0       AlbrechtstraÃŸe   \n",
       "3        48.161991  11.58654                1.0   Anni-Albers-StraÃŸe   \n",
       "4        48.139400  11.58888                1.0        NordendstraÃŸe   \n",
       "...            ...       ...                ...                  ...   \n",
       "2804142  48.161251  11.59206                1.0    MÃ¼nchner Freiheit   \n",
       "2804143  48.162029  11.56343                1.0    MÃ¼nchner Freiheit   \n",
       "2804144  48.180382  11.59943                1.0    MÃ¼nchner Freiheit   \n",
       "2804145  48.162739  11.57268                1.0    MÃ¼nchner Freiheit   \n",
       "2804146  48.157879  11.57722                1.0    MÃ¼nchner Freiheit   \n",
       "\n",
       "         RETURN_IS_STATION      RETURN_STATION_NAME  \n",
       "0                      1.0     Am Sportpark Neuried  \n",
       "1                      1.0  Kraillinger Weg Neuried  \n",
       "2                      1.0            Rotkreuzplatz  \n",
       "3                      1.0        MÃ¼nchner Freiheit  \n",
       "4                      1.0                    Lehel  \n",
       "...                    ...                      ...  \n",
       "2804142                0.0                      NaN  \n",
       "2804143                0.0                      NaN  \n",
       "2804144                0.0                      NaN  \n",
       "2804145                0.0                      NaN  \n",
       "2804146                0.0                      NaN  \n",
       "\n",
       "[2804147 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_raw_data(GCP_PROJECT, query=query, cache_path=Path(f'{LOCAL_DATA_PATH}/raw/MVG_Rad_Fahrten_{START_YEAR}_to_{END_YEAR}.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "base_url = 'https://archive-api.open-meteo.com/v1/archive'\n",
    "\n",
    "params = {\n",
    "    'latitude': 48.70,\n",
    "    'longitude': 13.46,\n",
    "    'start_date' : f'{START_YEAR}-01-01',\n",
    "    'end_date' : f'{END_YEAR}-12-31',\n",
    "    'hourly': ['temperature_2m', 'relativehumidity_2m', 'apparent_temperature','windspeed_10m','precipitation']\n",
    "}\n",
    "\n",
    "historical_weather_data = requests.get(base_url , params=params).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load data from local CSV...\u001b[0m\n",
      "âœ… Data loaded, with shape (35064, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relativehumidity_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>windspeed_10m</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01T00:00</td>\n",
       "      <td>3.3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01T01:00</td>\n",
       "      <td>3.4</td>\n",
       "      <td>99</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01T02:00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01T03:00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01T04:00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2022-12-31T19:00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>83</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2022-12-31T20:00</td>\n",
       "      <td>5.9</td>\n",
       "      <td>83</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2022-12-31T21:00</td>\n",
       "      <td>5.8</td>\n",
       "      <td>81</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2022-12-31T22:00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>78</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>2022-12-31T23:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>77</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time  temperature_2m  relativehumidity_2m  \\\n",
       "0      2019-01-01T00:00             3.3                  100   \n",
       "1      2019-01-01T01:00             3.4                   99   \n",
       "2      2019-01-01T02:00             3.5                  100   \n",
       "3      2019-01-01T03:00             3.5                   99   \n",
       "4      2019-01-01T04:00             3.5                  100   \n",
       "...                 ...             ...                  ...   \n",
       "35059  2022-12-31T19:00             6.5                   83   \n",
       "35060  2022-12-31T20:00             5.9                   83   \n",
       "35061  2022-12-31T21:00             5.8                   81   \n",
       "35062  2022-12-31T22:00             6.1                   78   \n",
       "35063  2022-12-31T23:00             6.0                   77   \n",
       "\n",
       "       apparent_temperature  windspeed_10m  precipitation  \n",
       "0                       0.5            9.0            0.2  \n",
       "1                       0.4            9.7            0.1  \n",
       "2                       0.2           12.0            0.2  \n",
       "3                       0.0           13.5            0.1  \n",
       "4                      -0.0           14.1            0.0  \n",
       "...                     ...            ...            ...  \n",
       "35059                   3.9            8.0            0.0  \n",
       "35060                   3.4            6.8            0.0  \n",
       "35061                   3.1            7.2            0.0  \n",
       "35062                   3.1            8.8            0.0  \n",
       "35063                   3.3            6.8            0.0  \n",
       "\n",
       "[35064 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_weather_data(cache_path=Path(f'{LOCAL_DATA_PATH}/raw/Histotical_Weather_Data_{START_YEAR}_to_{END_YEAR}.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Maxvorstadt': <POLYGON ((11.539 48.143, 11.54 48.143, 11.542 48.143, 11.544 48.142, 11.545...>,\n",
       " 'Schwabing-West': <POLYGON ((11.55 48.161, 11.55 48.161, 11.551 48.16, 11.551 48.16, 11.552 48...>,\n",
       " 'Au - Haidhausen': <POLYGON ((11.569 48.122, 11.569 48.122, 11.569 48.122, 11.57 48.122, 11.57 ...>,\n",
       " 'Sendling': <POLYGON ((11.535 48.13, 11.536 48.13, 11.536 48.13, 11.536 48.129, 11.536 4...>,\n",
       " 'SchwanthalerhÃ¶he': <POLYGON ((11.526 48.137, 11.526 48.137, 11.526 48.136, 11.526 48.136, 11.52...>,\n",
       " 'Moosach': <POLYGON ((11.466 48.205, 11.466 48.204, 11.467 48.204, 11.468 48.204, 11.46...>,\n",
       " 'Berg am Laim': <POLYGON ((11.601 48.124, 11.602 48.124, 11.604 48.123, 11.606 48.121, 11.60...>,\n",
       " 'Trudering': <POLYGON ((11.644 48.115, 11.644 48.115, 11.646 48.114, 11.647 48.113, 11.64...>,\n",
       " 'Ramersdorf': <POLYGON ((7.14 50.718, 7.143 50.718, 7.145 50.717, 7.147 50.717, 7.147 50.7...>,\n",
       " 'Obergiesing': <POLYGON ((11.574 48.112, 11.574 48.112, 11.574 48.112, 11.574 48.112, 11.57...>,\n",
       " 'Untergiesing': <POLYGON ((11.541 48.078, 11.542 48.078, 11.542 48.078, 11.542 48.078, 11.54...>,\n",
       " 'Harlaching': <POLYGON ((11.541 48.078, 11.542 48.078, 11.542 48.078, 11.542 48.078, 11.54...>,\n",
       " 'Thalkirchen': <POLYGON ((11.528 48.083, 11.528 48.083, 11.529 48.083, 11.529 48.083, 11.52...>,\n",
       " 'Obersendling': <POLYGON ((11.503 48.092, 11.503 48.092, 11.503 48.09, 11.503 48.089, 11.503...>,\n",
       " 'Hadern': <POLYGON ((11.463 48.105, 11.464 48.105, 11.465 48.105, 11.467 48.105, 11.46...>,\n",
       " 'Pasing': <POLYGON ((11.436 48.137, 11.437 48.136, 11.439 48.135, 11.438 48.135, 11.43...>,\n",
       " 'Obermenzing': <POLYGON ((11.433 48.163, 11.437 48.161, 11.437 48.161, 11.438 48.16, 11.439...>,\n",
       " 'Lochhausen': <POLYGON ((11.379 48.179, 11.381 48.177, 11.38 48.176, 11.38 48.176, 11.381 ...>,\n",
       " 'Langwied': <POLYGON ((13.06 47.83, 13.06 47.83, 13.06 47.83, 13.06 47.83, 13.061 47.829...>,\n",
       " 'Feldmoching': <POLYGON ((11.477 48.22, 11.477 48.22, 11.478 48.22, 11.479 48.22, 11.48 48....>,\n",
       " 'Laim': <POLYGON ((11.483 48.131, 11.483 48.131, 11.483 48.13, 11.484 48.13, 11.484 ...>,\n",
       " 'Ludwigsvorstadt-Isarvorstadt': <POLYGON ((11.544 48.126, 11.544 48.126, 11.544 48.126, 11.544 48.126, 11.54...>,\n",
       " 'Ramersdorf-Perlach': <POLYGON ((11.595 48.115, 11.595 48.115, 11.595 48.115, 11.595 48.115, 11.59...>,\n",
       " 'Untermenzing-Allach': <POLYGON ((11.43 48.189, 11.431 48.188, 11.431 48.188, 11.431 48.188, 11.431...>,\n",
       " 'Hasenbergl-Lerchenau Ost': <POLYGON ((11.539 48.189, 11.539 48.189, 11.539 48.189, 11.539 48.189, 11.53...>,\n",
       " 'SÃ¼dgiesing': <POLYGON ((11.585 48.1, 11.587 48.097, 11.588 48.095, 11.588 48.095, 11.588 ...>,\n",
       " 'Altstadt-Lehel': <POLYGON ((11.565 48.136, 11.565 48.136, 11.565 48.136, 11.565 48.136, 11.56...>,\n",
       " 'Sendling-Westpark': <POLYGON ((11.501 48.103, 11.501 48.103, 11.502 48.103, 11.502 48.102, 11.50...>,\n",
       " 'Neuhausen-Nymphenburg': <POLYGON ((11.481 48.158, 11.481 48.158, 11.481 48.158, 11.481 48.157, 11.48...>,\n",
       " 'Schwabing-Freimann': <POLYGON ((11.579 48.167, 11.579 48.167, 11.579 48.165, 11.579 48.164, 11.58...>,\n",
       " 'Pasing-Obermenzing': <POLYGON ((11.433 48.163, 11.437 48.161, 11.437 48.161, 11.438 48.16, 11.439...>,\n",
       " 'Aubing-Lochhausen-Langwied': <POLYGON ((11.361 48.158, 11.361 48.158, 11.361 48.158, 11.362 48.158, 11.36...>,\n",
       " 'Milbertshofen-Am Hart': <POLYGON ((11.538 48.168, 11.538 48.168, 11.539 48.168, 11.539 48.169, 11.54...>,\n",
       " 'Bogenhausen': <POLYGON ((11.595 48.142, 11.596 48.142, 11.596 48.142, 11.596 48.142, 11.59...>,\n",
       " 'Trudering-Riem': <POLYGON ((11.644 48.115, 11.644 48.115, 11.646 48.114, 11.647 48.113, 11.64...>,\n",
       " 'Untergiesing-Harlaching': <POLYGON ((11.541 48.078, 11.542 48.078, 11.542 48.078, 11.542 48.078, 11.54...>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = get_polygons()\n",
    "dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bike_sharing_demand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
